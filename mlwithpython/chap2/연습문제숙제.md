# Hands-on Machine Learning 4장
## 연습문제 9번
179쪽
편향/분산 tradoff
* 편향
 편향은 잘못된 가정에 인한 것. 편향이 큰 모델은 training data 에 과소적합이 쉽게됨
* 분산
 분산은 training data 의 작은 변동이 모델에 과도하게 반영될 때 나타나는 현상. 자유도가 높은 모델이 높은 분산을 가지기 쉬워 training data 에 과대적합(overfitting)
 
 모델의 복잡도 증가 -> 분산 증가, 편향 감소
 모델의 복잡도 감소 -> 분산 감소, 편향 증가
 
 9번 문제의 경우 
 
 9. 릿지 회귀를 사용했을 때 훈련 오차와 검증 오차가 거의 비슷하고 둘 다 높았습니다. 이 모델에는 높은 편향이 문제인가요, 아니면 높은 분산이 문제인가요? 규제 하이퍼파라미터 alpha를 증가시켜야 할까요, 줄여야 할까요?
 
  이 문제의 경우 training set 에 대한 오차가 높은 경우이고 이럴 경우는 편향이 증가되어있는 경우이다.
  이에 따라서 모델의 복잡도를 증가시켜야 하고 이러기 위해서는 \alpha 를 감소시켜야 한다. (부교제 그림 4-17 을 보면 \alpha 가 증가하면 모델이 선형에 가까워지고 \alpha 가 감소하면 모델이 다차방정식형태로 복잡해 지는 것을 볼 수 있다)
 
## 연습문제 10번
10. 다음과 같이 사용해야 하는 이유는?
 * 평범한 선형 회귀 대신 릿지 회귀
 * 릿지 회귀 대신 라쏘 회귀
 * 라쏘 회귀 대신 엘라스틱넷
 
  일반적으로 규제항이 있는 릿지가 더 좋은 성능을 보이기 때문에 릿지 회귀를 쓴다
  
  하지만 일부의 특성 값들만이 의미가 있다는 확신이 있다면 특성값에 대한 가중치를 `0`으로 만드는 라쏘를 쓰는 것이 좋다
  
  하지만 샘플의 갯수가 특성 값보다 적거나 할 때는 일반적으로 일라스틱넷이 라쏘보다 성능이 더 좋다고 알려져 있다고 한다.
 
